{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom scipy.signal import savgol_filter\n\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.model_selection import KFold, cross_val_predict, train_test_split\nimport piplite\nawait piplite.install('seaborn')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom scipy.stats import randint\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data = pd.read_csv(\"data.csv\")\ndata         ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data.drop('id', axis=1, inplace=True)\ndata['diagnosis'] = data['diagnosis'].replace('M', 0)\ndata['diagnosis'] = data['diagnosis'].replace('B', 1)\ndata.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Malignant, Benign = data.diagnosis.value_counts()\nMalignant, Benign",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data.drop([\"perimeter_mean\",\"perimeter_se\",\"perimeter_worst\"], axis = \"columns\", inplace = True)\ndata.drop([\"Radius_mean\",\"radius_se\", \"radius_worst\"], axis = \"columns\",inplace=True)\ndata.drop([\"symmetry_se\",\"texture_se\",\"smoothness_se\",\"fractal_dimension_se\"],axis=\"columns\",inplace=True)\ndata.drop(\"fractal_dimension_mean\",axis=\"columns\",inplace=True)\ndata.drop(\"Texture_mean\",axis=\"columns\", inplace=True)\ndata.drop([\"area_mean\",\"compactness_worst\"], axis=\"columns\",inplace=True)\nplt.figure(figsize=(25,20))\nsns.heatmap(data=data.corr(),annot=True)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x = data.drop(columns=['diagnosis'])\ny = data.diagnosis",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =0.25, random_state=42)\npls = PLSRegression()\npred = pls.fit(x_train,y_train)\ny_pred=pls.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "train_score= pls.score(x_train, y_train)\ntest_score = pls.score(x_test, y_test)\nprint(\"training score:\", train_score, \"\\ntest score:\", test_score)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.ensemble import RandomForestClassifier\nrf  = RandomForestClassifier() # PLS does not have the predict_proba attribute so random forest was used \npred = rf.fit(x_train, y_train)\ny_scores = rf.predict_proba(x_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_scores[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label=\"ROC curve (area = %0.2f)\" % roc_auc)\nplt.plot([0,1],[0,1], linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend()\nplt.show",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n# Since PLS uses regression, confusion matrix can't be found, LDA was used to find the confusion matrix\nlda = LinearDiscriminantAnalysis()\npred = lda.fit(x_train,y_train)\ny_pred=lda.predict(x_test)\n\ncm = confusion_matrix(y_test, y_pred)\naccuracy_score(y_test, y_pred)\ns = sns.heatmap(cm, annot=True)\ns.set(xlabel='Predicted', ylabel='True')",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}